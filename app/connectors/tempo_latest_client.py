"""
Connecteur TEMPO pour les derni√®res donn√©es disponibles
Recherche les donn√©es TEMPO des derniers jours au lieu du temps r√©el uniquement
"""
import asyncio
import earthaccess
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional, List
import aiohttp
from dotenv import load_dotenv
import os
import xarray as xr
import numpy as np
import tempfile
import numpy as np
import tempfile

# Chargement des variables d'environnement
env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')
load_dotenv(env_path)

logger = logging.getLogger(__name__)

class TempoLatestDataClient:
    """
    Client TEMPO sp√©cialis√© pour r√©cup√©rer les derni√®res donn√©es disponibles
    Recherche sur une p√©riode √©tendue pour maximiser les chances de trouver des donn√©es
    """
    
    def __init__(self):
        self.authenticated = False
        self.max_search_days = 7  # Rechercher sur les 7 derniers jours
        
        # Collections TEMPO avec leurs concepts
        self.tempo_collections = {
            'no2': {
                'concept_id': 'C2765522927-GES_DISC',
                'short_name': 'TEMPO_NO2_L2',
                'description': 'TEMPO Nitrogen Dioxide (NO2) Total Column'
            },
            'hcho': {
                'concept_id': 'C2765526899-GES_DISC', 
                'short_name': 'TEMPO_HCHO_L2',
                'description': 'TEMPO Formaldehyde (HCHO) Total Column'
            },
            'aerosol': {
                'concept_id': 'C2765525281-GES_DISC',
                'short_name': 'TEMPO_AOD_L2',
                'description': 'TEMPO Aerosol Optical Depth'
            },
            'o3': {
                'concept_id': 'C2765524647-GES_DISC',
                'short_name': 'TEMPO_O3TOT_L2', 
                'description': 'TEMPO Ozone (O3) Total Column'
            }
        }
        
    async def authenticate(self):
        """Authentification NASA Earthdata"""
        if self.authenticated:
            return True
            
        try:
            username = os.getenv('NASA_EARTHDATA_USERNAME')
            password = os.getenv('NASA_EARTHDATA_PASSWORD')
            
            if not username or not password:
                logger.error("‚ùå Identifiants NASA Earthdata manquants")
                return False
            
            # Authentification earthaccess (version corrig√©e)
            auth = earthaccess.login(persist=True)
            if auth.authenticated:
                self.authenticated = True
                logger.info("‚úÖ Authentification NASA Earthdata r√©ussie (mode Latest)")
                return True
            else:
                logger.error("‚ùå √âchec authentification earthaccess")
                return False
            
        except Exception as e:
            logger.error(f"‚ùå Erreur authentification TEMPO Latest: {e}")
            return False
    
    async def get_latest_available_data(self, lat: float, lon: float) -> Dict:
        """
        R√©cup√®re les derni√®res donn√©es TEMPO disponibles - VERSION RAPIDE (m√©tadonn√©es seulement)
        """
        if not await self.authenticate():
            return {}
        
        logger.info(f"üõ∞Ô∏è Recherche RAPIDE des m√©tadonn√©es TEMPO ({self.max_search_days} jours)")
        
        all_data = {}
        
        # Rechercher chaque polluant sur la p√©riode - M√âTADONN√âES SEULEMENT
        for pollutant, config in self.tempo_collections.items():
            logger.info(f"üîç Recherche {pollutant.upper()} r√©cent (m√©tadonn√©es)...")
            
            # Version rapide - pas de t√©l√©chargement
            data = await self._search_pollutant_metadata_only(
                pollutant, config, lat, lon
            )
            
            if data:
                all_data[pollutant] = data
                logger.info(f"‚úÖ {pollutant.upper()} trouv√©: {data.get('date', 'Unknown date')}")
            else:
                logger.warning(f"‚ö†Ô∏è {pollutant.upper()} non disponible (p√©riode: {self.max_search_days} jours)")
        
        if all_data:
            # Ajouter m√©tadonn√©es
            all_data['search_period_days'] = self.max_search_days
            all_data['coordinates'] = [lat, lon]
            all_data['data_source'] = 'TEMPO Latest Available'
            all_data['retrieved_at'] = datetime.utcnow().isoformat() + 'Z'
            
            logger.info(f"üéØ Donn√©es TEMPO r√©centes trouv√©es: {list(all_data.keys())}")
        
        return all_data
    
    async def _search_pollutant_recent(self, pollutant: str, config: Dict, lat: float, lon: float) -> Optional[Dict]:
        """
        Recherche un polluant sp√©cifique et extrait les vraies valeurs de concentration
        """
        try:
            # Recherche sur p√©riode √©tendue
            end_date = datetime.utcnow()
            start_date = end_date - timedelta(days=self.max_search_days)
            
            # Recherche des granules
            results = earthaccess.search_data(
                short_name=config['short_name'],
                bounding_box=(lon-0.5, lat-0.5, lon+0.5, lat+0.5),
                temporal=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')),
                count=10  # Prendre moins de granules pour extraire les donn√©es
            )
            
            if not results:
                return None
            
            # Prendre le granule le plus r√©cent
            latest_granule = results[-1]
            
            # Extraire les m√©tadonn√©es
            granule_date = self._extract_granule_date(latest_granule)
            
            # T√©l√©charger et extraire la vraie valeur de concentration
            concentration_data = await self._extract_concentration_from_granule(
                latest_granule, pollutant, lat, lon
            )
            
            if concentration_data:
                return {
                    'pollutant': pollutant,
                    'concentration': concentration_data['value'],
                    'unit': concentration_data['unit'],
                    'date': granule_date,
                    'granule_id': getattr(latest_granule, 'id', 'Unknown'),
                    'collection': config['short_name'],
                    'description': config['description'],
                    'coordinates': [lat, lon],
                    'quality_flag': concentration_data.get('quality', 'good'),
                    'data_source': 'TEMPO Satellite',
                    'note': f'Concentration extraite du granule TEMPO'
                }
            else:
                # Fallback si extraction √©choue - retourner m√©tadonn√©es
                return {
                    'pollutant': pollutant,
                    'concentration': None,
                    'unit': self._get_default_unit(pollutant),
                    'date': granule_date,
                    'granule_id': getattr(latest_granule, 'id', 'Unknown'),
                    'collection': config['short_name'],
                    'description': config['description'],
                    'coordinates': [lat, lon],
                    'available': True,
                    'note': f'Granule disponible mais concentration non extraite'
                }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche {pollutant}: {e}")
            return None
    
    async def _extract_concentration_from_granule(self, granule, pollutant: str, lat: float, lon: float) -> Optional[Dict]:
        """
        Extrait les m√©tadonn√©es du granule TEMPO SANS t√©l√©chargement pour √©viter les timeouts
        Version optimis√©e pour la rapidit√©
        """
        try:
            granule_metadata = {
                'granule_id': getattr(granule, 'id', 'Unknown'),
                'time_start': getattr(granule, 'time_start', 'Unknown'),
                'time_end': getattr(granule, 'time_end', 'Unknown'),
                'size_mb': getattr(granule, 'granule_size', 0) / 1024 / 1024 if hasattr(granule, 'granule_size') else 0,
                'extraction_method': 'metadata_only',
                'pollutant': pollutant,
                'coordinates': {'lat': lat, 'lon': lon},
                'available': True,
                'value': f"Granule disponible - {pollutant.upper()}",
                'unit': self._get_default_unit(pollutant)
            }
            
            logger.info(f"‚úÖ {pollutant.upper()} trouv√©: {granule_metadata.get('time_start', 'N/A')} (m√©tadonn√©es seulement)")
            return granule_metadata
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur extraction m√©tadonn√©es {pollutant}: {e}")
            return None
            logger.info(f"üì• T√©l√©chargement du granule {pollutant.upper()}...")
            
            # Cr√©er un r√©pertoire temporaire
            with tempfile.TemporaryDirectory() as temp_dir:
                # T√©l√©charger le fichier
                downloaded_files = earthaccess.download(granule, temp_dir)
                
                if not downloaded_files:
                    logger.warning(f"‚ö†Ô∏è √âchec t√©l√©chargement {pollutant}")
                    return None
                
                # Lire le fichier NetCDF
                file_path = downloaded_files[0]
                concentration = await self._read_netcdf_concentration(
                    file_path, pollutant, lat, lon
                )
                
                return concentration
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur extraction {pollutant}: {e}")
            return None
    
    async def _read_netcdf_concentration(self, file_path: str, pollutant: str, lat: float, lon: float) -> Optional[Dict]:
        """
        Lit le fichier NetCDF et extrait la concentration au point g√©ographique
        """
        try:
            import xarray as xr
            
            # Ouvrir le dataset NetCDF
            with xr.open_dataset(file_path) as ds:
                
                # Variables typiques pour chaque polluant TEMPO
                variable_mapping = {
                    'no2': 'nitrogen_dioxide_total_column',
                    'hcho': 'formaldehyde_total_column', 
                    'aerosol': 'aerosol_optical_depth',
                    'o3': 'ozone_total_column'
                }
                
                # Chercher la variable dans le dataset
                var_name = None
                for possible_name in [variable_mapping.get(pollutant), f'{pollutant}_column', pollutant]:
                    if possible_name and possible_name in ds.variables:
                        var_name = possible_name
                        break
                
                # Si pas trouv√©, prendre la premi√®re variable de donn√©es
                if not var_name:
                    data_vars = [v for v in ds.data_vars if len(ds[v].dims) >= 2]
                    if data_vars:
                        var_name = data_vars[0]
                        logger.info(f"üìä Utilisation de la variable: {var_name}")
                
                if not var_name:
                    logger.warning("‚ö†Ô∏è Aucune variable de donn√©es trouv√©e")
                    return None
                
                # Extraire les coordonn√©es
                data_array = ds[var_name]
                
                # Trouver les indices les plus proches de lat/lon
                if 'latitude' in ds.coords and 'longitude' in ds.coords:
                    lat_idx = np.abs(ds.latitude - lat).argmin()
                    lon_idx = np.abs(ds.longitude - lon).argmin()
                    
                    # Extraire la valeur
                    if len(data_array.dims) == 2:
                        value = float(data_array.isel(latitude=lat_idx, longitude=lon_idx).values)
                    else:
                        # Prendre le premier temps si dimension temporelle
                        value = float(data_array.isel(latitude=lat_idx, longitude=lon_idx).values.flatten()[0])
                    
                    # V√©rifier si la valeur est valide
                    if np.isnan(value) or np.isinf(value):
                        logger.warning(f"‚ö†Ô∏è Valeur invalide pour {pollutant}: {value}")
                        return None
                    
                    # Obtenir l'unit√©
                    unit = getattr(data_array, 'units', self._get_default_unit(pollutant))
                    
                    return {
                        'value': round(value, 6),
                        'unit': unit,
                        'quality': 'good',
                        'variable_name': var_name
                    }
                else:
                    logger.warning("‚ö†Ô∏è Coordonn√©es latitude/longitude non trouv√©es")
                    return None
                    
        except ImportError:
            logger.error("‚ùå xarray requis pour lire les fichiers NetCDF")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur lecture NetCDF: {e}")
            return None
    
    def _get_default_unit(self, pollutant: str) -> str:
        """Retourne l'unit√© par d√©faut pour chaque polluant"""
        units = {
            'no2': 'molecules/cm¬≤',
            'hcho': 'molecules/cm¬≤', 
            'aerosol': 'unitless',
            'o3': 'DU'
        }
        return units.get(pollutant, 'unknown')
    
    def _extract_granule_date(self, granule) -> str:
        """Extrait la date du granule"""
        try:
            # Essayer d'extraire la date depuis les m√©tadonn√©es
            if hasattr(granule, 'temporal'):
                temporal = granule.temporal
                if temporal and len(temporal) > 0:
                    return temporal[0].strftime('%Y-%m-%d %H:%M:%S UTC')
            
            # Fallback: utiliser la date de cr√©ation
            if hasattr(granule, 'meta') and 'native-id' in granule.meta:
                native_id = granule.meta['native-id']
                # Extraire la date du nom du fichier si possible
                if 'TEMPO' in native_id:
                    # Format typique: TEMPO_[PRODUCT]_L2_[YYYYMMDD]T[HHMMSS]...
                    import re
                    date_match = re.search(r'(\d{8})T(\d{6})', native_id)
                    if date_match:
                        date_str = date_match.group(1)
                        time_str = date_match.group(2)
                        return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]} {time_str[:2]}:{time_str[2:4]}:{time_str[4:6]} UTC"
            
            return datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Impossible d'extraire la date du granule: {e}")
            return "Date inconnue"
    
    async def get_data_summary(self, lat: float, lon: float) -> Dict:
        """
        R√©cup√®re un r√©sum√© des donn√©es TEMPO disponibles sans les d√©tails complets
        """
        if not await self.authenticate():
            return {'error': 'Authentication failed'}
        
        summary = {
            'location': [lat, lon],
            'search_period_days': self.max_search_days,
            'pollutants_available': [],
            'latest_dates': {},
            'total_granules_found': 0
        }
        
        for pollutant, config in self.tempo_collections.items():
            try:
                end_date = datetime.utcnow()
                start_date = end_date - timedelta(days=self.max_search_days)
                
                results = earthaccess.search_data(
                    short_name=config['short_name'],
                    bounding_box=(lon-0.5, lat-0.5, lon+0.5, lat+0.5),
                    temporal=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')),
                    count=10
                )
                
                if results:
                    summary['pollutants_available'].append(pollutant)
                    summary['total_granules_found'] += len(results)
                    
                    # Date du plus r√©cent
                    latest_date = self._extract_granule_date(results[-1])
                    summary['latest_dates'][pollutant] = latest_date
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur r√©sum√© {pollutant}: {e}")
        
        summary['status'] = 'success' if summary['pollutants_available'] else 'no_data'
        return summary

    async def _search_pollutant_metadata_only(self, pollutant: str, config: Dict, lat: float, lon: float) -> Optional[Dict]:
        """
        Recherche RAPIDE - m√©tadonn√©es seulement, pas de t√©l√©chargement
        """
        try:
            end_date = datetime.utcnow()
            start_date = end_date - timedelta(days=self.max_search_days)
            
            # Recherche avec une zone g√©ographique
            granules = earthaccess.search_data(
                short_name=config['short_name'],
                bounding_box=(lon-0.5, lat-0.5, lon+0.5, lat+0.5),
                temporal=(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')),
                count=5  # Limite pour rapidit√©
            )
            
            if not granules:
                return None
            
            # Prendre le plus r√©cent
            latest_granule = granules[-1]
            granule_date = self._extract_granule_date(latest_granule)
            
            # Retourner m√©tadonn√©es seulement - PAS de t√©l√©chargement
            return {
                'pollutant': pollutant,
                'concentration': 'M√©tadonn√©es disponibles',
                'unit': self._get_default_unit(pollutant),
                'date': granule_date,
                'granule_id': getattr(latest_granule, 'id', 'Unknown'),
                'collection': config['short_name'],
                'description': config['description'],
                'coordinates': [lat, lon],
                'available': True,
                'extraction_method': 'metadata_only_fast',
                'data_source': 'TEMPO Satellite',
                'note': f'Granule TEMPO disponible - extraction rapide sans t√©l√©chargement'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche m√©tadonn√©es {pollutant}: {e}")
            return None

    async def get_search_metadata_only(self, lat: float, lon: float) -> Dict:
        """
        Version ultra-rapide : recherche m√©tadonn√©es seulement sans t√©l√©chargement
        """
        try:
            # Utiliser la m√©thode d'authentification existante
            if not await self.authenticate():
                return {'available': False, 'reason': 'authentication_failed'}
            
            logger.info(f"üîç Recherche m√©tadonn√©es TEMPO rapide: {lat}, {lon}")
            
            products_found = []
            for pollutant in ['no2', 'hcho', 'o3']:
                try:
                    config = self.tempo_collections[pollutant]  # Utiliser tempo_collections
                    
                    # Recherche simple avec limite
                    granules = earthaccess.search_data(
                        short_name=config['short_name'],
                        version=config['version'],
                        temporal=(
                            (datetime.now() - timedelta(days=2)).strftime("%Y-%m-%d"),
                            datetime.now().strftime("%Y-%m-%d")
                        ),
                        count=3  # Limite √† 3 granules
                    )
                    
                    if granules:
                        products_found.append({
                            'pollutant': pollutant,
                            'count': len(granules),
                            'last_granule': granules[0].get('time_start', 'N/A'),
                            'collection': config['short_name']
                        })
                
                except Exception as e:
                    logger.warning(f"Erreur recherche {pollutant}: {e}")
                    continue
            
            return {
                'available': len(products_found) > 0,
                'products': products_found,
                'retrieved_at': datetime.now().isoformat(),
                'search_method': 'metadata_only',
                'coordinates': {'lat': lat, 'lon': lon}
            }
            
        except Exception as e:
            logger.error(f"Erreur recherche m√©tadonn√©es: {e}")
            return {'available': False, 'reason': str(e)}

    async def get_metadata_only(self, lat: float, lon: float) -> Dict:
        """Alias pour compatibilit√©"""
        return await self.get_search_metadata_only(lat, lon)