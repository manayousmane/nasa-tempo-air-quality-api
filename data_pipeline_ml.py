#!/usr/bin/env python3
"""
ğŸ­ DATA PIPELINE POUR MODÃˆLES ML
================================================================================
Transforme les donnÃ©es d'API en features utilisables pour machine learning
================================================================================
"""

import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import json
import sys
from pathlib import Path

sys.path.append('.')

from app.services.air_quality_service import AirQualityService
from app.core.logging import get_logger

logger = get_logger(__name__)

class AirQualityDataPipeline:
    """Pipeline de transformation des donnÃ©es air quality pour ML"""
    
    def __init__(self):
        self.air_service = AirQualityService()
        self.feature_columns = []
        self.target_columns = []
        
        # Configuration des polluants cibles
        self.target_pollutants = [
            'PM2.5', 'PM10', 'NO2', 'O3', 'CO', 'SO2'
        ]
        
        # Configuration des features mÃ©tÃ©o
        self.weather_features = [
            'temperature', 'humidity', 'pressure', 'wind_speed', 
            'wind_direction', 'precipitation'
        ]
        
        # Configuration temporelle
        self.temporal_features = [
            'hour', 'day_of_week', 'month', 'season',
            'is_weekend', 'is_holiday'
        ]
        
        # Configuration gÃ©ospatiale  
        self.spatial_features = [
            'latitude', 'longitude', 'elevation', 'population_density',
            'urban_index', 'industrial_index'
        ]
    
    async def collect_raw_data(self, 
                               locations: List[Tuple[float, float]], 
                               hours_back: int = 24) -> List[Dict]:
        """Collecte donnÃ©es brutes pour plusieurs locations"""
        logger.info(f"ğŸ”„ Collecte donnÃ©es pour {len(locations)} locations")
        
        collected_data = []
        
        for lat, lon in locations:
            try:
                logger.info(f"ğŸ“ Collecte: {lat}, {lon}")
                
                # DonnÃ©es actuelles
                current_data = await self.air_service.get_air_quality_indices(lat, lon)
                
                if current_data:
                    # Extraction des mesures individuelles
                    raw_measurements = await self._extract_raw_measurements(lat, lon)
                    
                    location_data = {
                        'latitude': lat,
                        'longitude': lon,
                        'timestamp': datetime.now(),
                        'current_data': current_data,
                        'raw_measurements': raw_measurements
                    }
                    
                    collected_data.append(location_data)
                    logger.info(f"âœ… DonnÃ©es collectÃ©es: {lat}, {lon}")
                else:
                    logger.warning(f"âš ï¸ Aucune donnÃ©e: {lat}, {lon}")
                    
            except Exception as e:
                logger.error(f"âŒ Erreur collecte {lat}, {lon}: {str(e)}")
        
        logger.info(f"âœ… Collecte terminÃ©e: {len(collected_data)}/{len(locations)}")
        return collected_data
    
    async def _extract_raw_measurements(self, lat: float, lon: float) -> Dict:
        """Extrait les mesures brutes des collecteurs"""
        try:
            # Utilisation directe des collecteurs pour donnÃ©es brutes
            from app.collectors.open_source_collectors import OpenSourceCollectors
            
            collectors = OpenSourceCollectors()
            raw_data = await collectors.collect_all_sources(lat, lon)
            
            measurements = {}
            
            for source_name, source_data in raw_data.items():
                if source_data and 'measurements' in source_data:
                    for measurement in source_data['measurements']:
                        pollutant = measurement.get('pollutant', '')
                        value = measurement.get('value')
                        unit = measurement.get('unit', '')
                        
                        if pollutant and value is not None:
                            measurements[f"{pollutant}_{source_name}"] = {
                                'value': float(value),
                                'unit': unit,
                                'source': source_name,
                                'timestamp': measurement.get('timestamp', datetime.now().isoformat())
                            }
            
            return measurements
            
        except Exception as e:
            logger.error(f"âŒ Erreur extraction mesures: {str(e)}")
            return {}
    
    def create_feature_matrix(self, raw_data: List[Dict]) -> pd.DataFrame:
        """CrÃ©e la matrice de features pour ML"""
        logger.info("ğŸ”§ CrÃ©ation matrice de features")
        
        features_list = []
        
        for location_data in raw_data:
            try:
                features = {}
                
                # Features de base
                features['latitude'] = location_data['latitude']
                features['longitude'] = location_data['longitude']
                features['timestamp'] = pd.to_datetime(location_data['timestamp'])
                
                # Features temporelles
                timestamp = location_data['timestamp']
                features.update(self._extract_temporal_features(timestamp))
                
                # Features gÃ©ospatiales
                features.update(self._extract_spatial_features(
                    location_data['latitude'], 
                    location_data['longitude']
                ))
                
                # Features polluants (valeurs actuelles)
                if 'raw_measurements' in location_data:
                    features.update(self._extract_pollutant_features(
                        location_data['raw_measurements']
                    ))
                
                # Features mÃ©tÃ©o (simulÃ©es pour l'instant)
                features.update(self._extract_weather_features(
                    location_data['latitude'], 
                    location_data['longitude']
                ))
                
                features_list.append(features)
                
            except Exception as e:
                logger.error(f"âŒ Erreur crÃ©ation features: {str(e)}")
        
        df = pd.DataFrame(features_list)
        logger.info(f"âœ… Matrice crÃ©Ã©e: {df.shape}")
        
        return df
    
    def _extract_temporal_features(self, timestamp: datetime) -> Dict:
        """Extrait les features temporelles"""
        return {
            'hour': timestamp.hour,
            'day_of_week': timestamp.weekday(),
            'month': timestamp.month,
            'season': (timestamp.month % 12 + 3) // 3,  # 1=winter, 2=spring, etc.
            'is_weekend': 1 if timestamp.weekday() >= 5 else 0,
            'is_holiday': 0,  # Ã€ implÃ©menter avec calendrier des jours fÃ©riÃ©s
            'hour_sin': np.sin(2 * np.pi * timestamp.hour / 24),
            'hour_cos': np.cos(2 * np.pi * timestamp.hour / 24),
            'day_sin': np.sin(2 * np.pi * timestamp.weekday() / 7),
            'day_cos': np.cos(2 * np.pi * timestamp.weekday() / 7)
        }
    
    def _extract_spatial_features(self, lat: float, lon: float) -> Dict:
        """Extrait les features gÃ©ospatiales"""
        # Approximations basiques - Ã  amÃ©liorer avec vraies donnÃ©es gÃ©o
        return {
            'elevation': 0,  # Ã€ rÃ©cupÃ©rer via API elevation
            'population_density': self._estimate_population_density(lat, lon),
            'urban_index': self._estimate_urban_index(lat, lon),
            'industrial_index': self._estimate_industrial_index(lat, lon),
            'distance_to_coast': self._estimate_distance_to_coast(lat, lon)
        }
    
    def _extract_pollutant_features(self, measurements: Dict) -> Dict:
        """Extrait les features des polluants"""
        features = {}
        
        for pollutant in self.target_pollutants:
            # Cherche toutes les sources pour ce polluant
            values = []
            for key, measurement in measurements.items():
                if pollutant in key:
                    values.append(measurement['value'])
            
            if values:
                features[f"{pollutant}_mean"] = np.mean(values)
                features[f"{pollutant}_std"] = np.std(values) if len(values) > 1 else 0
                features[f"{pollutant}_min"] = np.min(values)
                features[f"{pollutant}_max"] = np.max(values)
                features[f"{pollutant}_count"] = len(values)
            else:
                # Valeurs par dÃ©faut si pas de donnÃ©es
                features[f"{pollutant}_mean"] = np.nan
                features[f"{pollutant}_std"] = 0
                features[f"{pollutant}_min"] = np.nan
                features[f"{pollutant}_max"] = np.nan
                features[f"{pollutant}_count"] = 0
        
        return features
    
    def _extract_weather_features(self, lat: float, lon: float) -> Dict:
        """Extrait les features mÃ©tÃ©o (simulÃ©es pour l'instant)"""
        # Simulation basique - Ã  remplacer par vraie API mÃ©tÃ©o
        import random
        random.seed(int(lat * lon * 1000))  # Seed dÃ©terministe
        
        return {
            'temperature': 15 + random.uniform(-10, 20),
            'humidity': 40 + random.uniform(0, 40),
            'pressure': 1013 + random.uniform(-20, 20),
            'wind_speed': random.uniform(0, 15),
            'wind_direction': random.uniform(0, 360),
            'precipitation': random.uniform(0, 10)
        }
    
    def _estimate_population_density(self, lat: float, lon: float) -> float:
        """Estime la densitÃ© de population (Ã  amÃ©liorer)"""
        # Approximation basique basÃ©e sur les grandes villes
        major_cities = [
            (40.7128, -74.0060, 10000),  # NYC
            (34.0522, -118.2437, 8000),  # LA
            (48.8566, 2.3522, 9000),     # Paris
            (35.6762, 139.6503, 12000)   # Tokyo
        ]
        
        min_distance = float('inf')
        nearest_density = 1000  # DensitÃ© par dÃ©faut
        
        for city_lat, city_lon, density in major_cities:
            distance = np.sqrt((lat - city_lat)**2 + (lon - city_lon)**2)
            if distance < min_distance:
                min_distance = distance
                nearest_density = density
        
        # DÃ©croissance avec la distance
        return max(100, nearest_density / (1 + min_distance * 100))
    
    def _estimate_urban_index(self, lat: float, lon: float) -> float:
        """Estime l'indice urbain"""
        return min(1.0, self._estimate_population_density(lat, lon) / 5000)
    
    def _estimate_industrial_index(self, lat: float, lon: float) -> float:
        """Estime l'indice industriel"""
        # Approximation basique
        return 0.3  # Valeur par dÃ©faut
    
    def _estimate_distance_to_coast(self, lat: float, lon: float) -> float:
        """Estime la distance Ã  la cÃ´te"""
        # Approximation trÃ¨s basique
        return 100.0  # km par dÃ©faut
    
    def create_target_variables(self, raw_data: List[Dict], 
                                prediction_horizon: int = 1) -> pd.DataFrame:
        """CrÃ©e les variables cibles pour prÃ©diction"""
        logger.info(f"ğŸ¯ CrÃ©ation variables cibles (horizon: {prediction_horizon}h)")
        
        targets_list = []
        
        for location_data in raw_data:
            targets = {}
            
            # Variables cibles: concentrations futures des polluants
            if 'raw_measurements' in location_data:
                measurements = location_data['raw_measurements']
                
                for pollutant in self.target_pollutants:
                    # Pour l'instant, on utilise les valeurs actuelles
                    # Dans un vrai pipeline, on aurait les valeurs futures
                    values = []
                    for key, measurement in measurements.items():
                        if pollutant in key:
                            values.append(measurement['value'])
                    
                    if values:
                        targets[f"{pollutant}_future"] = np.mean(values)
                    else:
                        targets[f"{pollutant}_future"] = np.nan
            
            # Variables cibles: AQI futur
            targets['aqi_future'] = 50  # Valeur simulÃ©e
            targets['health_risk_level'] = 1  # 0=low, 1=moderate, 2=high, 3=very_high
            
            targets_list.append(targets)
        
        df = pd.DataFrame(targets_list)
        logger.info(f"âœ… Variables cibles crÃ©Ã©es: {df.shape}")
        
        return df
    
    def save_processed_data(self, features_df: pd.DataFrame, 
                           targets_df: pd.DataFrame, 
                           output_dir: str = "data/processed") -> Dict[str, str]:
        """Sauvegarde les donnÃ©es processÃ©es"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Sauvegarde features
        features_file = output_path / f"features_{timestamp}.csv"
        features_df.to_csv(features_file, index=False)
        
        # Sauvegarde targets
        targets_file = output_path / f"targets_{timestamp}.csv"
        targets_df.to_csv(targets_file, index=False)
        
        # MÃ©tadonnÃ©es
        metadata = {
            'timestamp': timestamp,
            'features_shape': features_df.shape,
            'targets_shape': targets_df.shape,
            'features_columns': list(features_df.columns),
            'targets_columns': list(targets_df.columns),
            'missing_values': {
                'features': features_df.isnull().sum().to_dict(),
                'targets': targets_df.isnull().sum().to_dict()
            }
        }
        
        metadata_file = output_path / f"metadata_{timestamp}.json"
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)
        
        logger.info(f"âœ… DonnÃ©es sauvegardÃ©es:")
        logger.info(f"   Features: {features_file}")
        logger.info(f"   Targets: {targets_file}")
        logger.info(f"   Metadata: {metadata_file}")
        
        return {
            'features_file': str(features_file),
            'targets_file': str(targets_file),
            'metadata_file': str(metadata_file)
        }

async def main():
    """Pipeline principal de transformation des donnÃ©es"""
    print("ğŸ­ PIPELINE DE TRANSFORMATION DES DONNÃ‰ES ML")
    print("=" * 80)
    print(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    pipeline = AirQualityDataPipeline()
    
    # Locations de test
    test_locations = [
        (40.7128, -74.0060),   # New York
        (34.0522, -118.2437),  # Los Angeles
        (48.8566, 2.3522),     # Paris
        (35.6762, 139.6503),   # Tokyo
        (51.5074, -0.1278),    # London
        (55.7558, 37.6173),    # Moscow
    ]
    
    try:
        # 1. Collecte des donnÃ©es brutes
        print("\nğŸ”„ Ã‰TAPE 1: Collecte donnÃ©es brutes")
        raw_data = await pipeline.collect_raw_data(test_locations)
        
        if not raw_data:
            print("âŒ Aucune donnÃ©e collectÃ©e")
            return
        
        # 2. CrÃ©ation matrice de features
        print("\nğŸ”§ Ã‰TAPE 2: CrÃ©ation matrice de features")
        features_df = pipeline.create_feature_matrix(raw_data)
        
        # 3. CrÃ©ation variables cibles
        print("\nğŸ¯ Ã‰TAPE 3: CrÃ©ation variables cibles")
        targets_df = pipeline.create_target_variables(raw_data)
        
        # 4. Sauvegarde
        print("\nğŸ’¾ Ã‰TAPE 4: Sauvegarde donnÃ©es processÃ©es")
        files = pipeline.save_processed_data(features_df, targets_df)
        
        # 5. RÃ©sumÃ©
        print("\n" + "=" * 80)
        print("ğŸ“Š RÃ‰SUMÃ‰ PIPELINE ML")
        print("=" * 80)
        print(f"âœ… Locations traitÃ©es: {len(raw_data)}")
        print(f"âœ… Features crÃ©Ã©es: {features_df.shape[1]}")
        print(f"âœ… Targets crÃ©Ã©es: {targets_df.shape[1]}")
        print(f"âœ… Ã‰chantillons: {features_df.shape[0]}")
        
        print(f"\nğŸ“ˆ Features principales:")
        for col in features_df.columns[:10]:  # Premiers 10
            print(f"   â€¢ {col}")
        
        print(f"\nğŸ¯ Variables cibles:")
        for col in targets_df.columns:
            print(f"   â€¢ {col}")
        
        print(f"\nğŸ’¾ Fichiers gÃ©nÃ©rÃ©s:")
        for key, file_path in files.items():
            print(f"   â€¢ {key}: {file_path}")
        
        print("\nğŸ‰ PIPELINE ML PRÃŠT!")
        print("ğŸ”„ Prochaines Ã©tapes: EntraÃ®nement des modÃ¨les")
        
    except Exception as e:
        print(f"âŒ Erreur pipeline: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())